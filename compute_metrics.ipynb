{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用 Object 格式\n",
    "\n",
    "每个 Object 可以抽象成一个 List，List 里面的每一项对应一个刚性部件。每个刚性部件可以用一个字典来描述，字典的格式如下（*代表非必须，依使用的功能而定）：\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"points\": n*3 np.ndarray,\n",
    "    \"joint_data_origin\": [x0, y0, z0],\n",
    "    \"joint_data_direction\": [x1, y1, z1],\n",
    "    \"limit\": [p_min, p_max, r_min, r_max],\n",
    "    \"dfn\": dfs number,\n",
    "    \"dfn_fa\": father's dfs number,\n",
    "    *\"shape_code\": latent code for genSDF,\n",
    "    *\"bbox_l\": [l_x, l_y, l_z],\n",
    "    *\"bbox_center\": [x_c, y_c, z_c],\n",
    "    *\"rho\": number of point per unit cube (1x1x1),\n",
    "    *\"mesh\": triMesh object,\n",
    "}\n",
    "```\n",
    "\n",
    "将该 List 直接使用 pickle 序列化为 .dat 格式，即可作为 ID 计算脚本的输入：\n",
    "\n",
    "```python\n",
    "obj = # List of PartDict\n",
    "path = \"<path_to_directory>\" / \"<name_of_object>.dat\"\n",
    "with open(path, 'wb') as f: \n",
    "    f.write(pickle.dumps(obj))\n",
    "```\n",
    "\n",
    "### Compute Metrics 参数设置\n",
    "\n",
    "该计算脚本基于运行环境：`conda activate pytorch3d`，可以通过 NAP 根目录下 metric_env.sh 构建。\n",
    "\n",
    "请在下面的代码块中填入正确的路径或文件名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir:  /root/workspace/csn4bls7v38s73cem970/cage\n",
      "output_name:  cage\n",
      "gt_name:  data_gt\n",
      "N_states:  10\n",
      "N_pcl:  4096\n",
      "result_dir:  /root/workspace/csn4bls7v38s73cem970/output/cage\n"
     ]
    }
   ],
   "source": [
    "# data_dir: same as '--data_dir' in instantiation_distance.py\n",
    "data_dir = \"/root/workspace/csn4bls7v38s73cem970/cage\"\n",
    "# data_dir = \"testin\"\n",
    "\n",
    "# output_name: directory name of '--data_dir' in instantiation_distance.py \n",
    "# gt_name: directory name of '--gt_dir' in instantiation_distance.py\n",
    "output_name = data_dir.split('/')[-1]\n",
    "gt_name = \"data_gt\"\n",
    "# gt_name = \"testgt\"\n",
    "\n",
    "# N_states: same as '--N_states' in instantiation_distance.py\n",
    "# N_pcl: same as '--N_pcl' in instantiation_distance.py\n",
    "# n_sample_POR: number of sample points in the Part Overlapport Ratio (POR) calculation, recommended to be not less than 4096\n",
    "N_states = 10\n",
    "N_pcl = 4096\n",
    "n_sample_POR = 4096\n",
    "\n",
    "# result_dir: same as '--output_dir' in instantiation_distance.py\n",
    "result_dir = '/root/workspace/csn4bls7v38s73cem970/output/cage'\n",
    "\n",
    "# sample_file_path: same as '--sample_file_path' in instantiation_distance.py\n",
    "sample_file_path = '/root/workspace/csn4bls7v38s73cem970/eval/selected_files.json'\n",
    "\n",
    "##########\n",
    "print(\"data_dir: \", data_dir)\n",
    "print(\"output_name: \", output_name)\n",
    "print(\"gt_name: \", gt_name)\n",
    "print(\"N_states: \", N_states)\n",
    "print(\"N_pcl: \", N_pcl)\n",
    "print(\"result_dir: \", result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Metrics 计算\n",
    "\n",
    "需要准备好 model output 和 gt files，分别放在两个文件夹下，文件夹里面就是.dat格式保存的obj dict文件，每个文件代表一个物品。\n",
    "参照 `compute_id.sh` 里的格式，填好参数并运行 `instantiation_distance.py`。\n",
    "\n",
    "之后把两个参数中的文件夹名，和计算脚本输出的目录填在下面，运行该代码块即可。\n",
    "\n",
    "### ID Metrics 解释\n",
    "\n",
    "- minimum matching distance (MMD) 对于每个生成样本，在源数据中找与它距离最小的作为match（minimum matching）。每个生成样本只统计和match的距离，对所有距离取平均得到这一指标。**描述个体维度的重建质量，数值越小越好。**\n",
    "- coverage (COV) 计算所有match的去重数量，除以输入样本的总数。**描述模型覆盖率，数值越大越好**。\n",
    "- 1-nearest neighbor accuracy (1-NNA) 直观上说，该指标的数值等于错误匹配的样本数量。**描述分布的相似度，数值越小越好。**\n",
    "\n",
    "1-NNA的计算过程：把输入样本和生成样本合并为一个大集合，对其进行最邻近聚类（1-NN Clustering）。记输入样本为1，生成样本为0，得到gt。再通过最邻近聚类重新预测标签，即把每个样本预测为它1-NN的gt类别，计算预测准确率，得到该值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>nan, nan, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>nan, nan, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>nan, nan, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>nan, nan, nan, nan, nan<span style=\"font-weight: bold\">]</span>,\n",
       "        <span style=\"font-weight: bold\">[</span>nan, nan, nan, nan, nan<span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0mnan, nan, nan, nan, nan\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0mnan, nan, nan, nan, nan\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0mnan, nan, nan, nan, nan\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0mnan, nan, nan, nan, nan\u001b[1m]\u001b[0m,\n",
       "        \u001b[1m[\u001b[0mnan, nan, nan, nan, nan\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">cage data_gt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "cage data_gt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-NN-ID-acc': tensor(1.),\n",
      " 'lgam_cov-ID': tensor(0.0106),\n",
      " 'lgan_mmd-ID': tensor(nan)}\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_ID\n",
    "\n",
    "# evaluate the instantiation distance\n",
    "eval_ID(result_dir, output_name, gt_name, N_states, N_pcl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POR Metric 计算\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">warning: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> objects are not found in data_dir.\n",
       "</pre>\n"
      ],
      "text/plain": [
       "warning: \u001b[1;36m6\u001b[0m objects are not found in data_dir.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_48859_0.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_48859_0.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_41083_2.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_41083_2.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_48010_2.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_48010_2.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_45636_1.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_45636_1.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_46856_2.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_46856_2.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">StorageFurniture_46197_0.dat\n",
       "</pre>\n"
      ],
      "text/plain": [
       "StorageFurniture_46197_0.dat\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching INPUT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:03<00:00, 29.03it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:01<00:00,  8.71it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 11.02it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.97it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.63it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.65it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:01<00:00,  5.33it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.66it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 11.02it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.50it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.40it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 11.01it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.27it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.58it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.96it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:01<00:00,  5.33it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:01<00:00,  5.34it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:03<00:00,  3.16it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.62it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.98it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.71it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:01<00:00,  5.35it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 93.18it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.67it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.76it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.79it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.98it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.45it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.62it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.19it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.54it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.64it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:03<00:00,  3.15it/s]\n",
      "Processing on different pose state.:  10%|█         | 1/10 [00:00<00:01,  5.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     DATA_IN\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m DATA_IN:\n\u001b[0;32m---> 26\u001b[0m     POR_mean, POR_max \u001b[38;5;241m=\u001b[39m \u001b[43mPOR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_sample_POR\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     27\u001b[0m     POR_max_list\u001b[38;5;241m.\u001b[39mappend(POR_max)\n\u001b[1;32m     28\u001b[0m     POR_mean_list\u001b[38;5;241m.\u001b[39mappend(POR_mean)\n",
      "File \u001b[0;32m~/workspace/csn4bls7v38s73cem970/eval/utils.py:374\u001b[0m, in \u001b[0;36mPOR\u001b[0;34m(obj, n_sample, n_states, conf_T)\u001b[0m\n\u001b[1;32m    371\u001b[0m                 ious\u001b[38;5;241m.\u001b[39mappend(iou)\n\u001b[1;32m    372\u001b[0m             \u001b[38;5;66;03m# if i == 0 and j == 2:\u001b[39;00m\n\u001b[1;32m    373\u001b[0m             \u001b[38;5;66;03m#     print(f\"State: {state}, Part {i} and Part {j}: {iou}\")\u001b[39;00m\n\u001b[0;32m--> 374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ious) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    375\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mtensor(ious)\u001b[38;5;241m.\u001b[39mmean())\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(results) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os, os.path as osp\n",
    "import pickle, json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import POR, sample_object, align_part_keys\n",
    "\n",
    "POR_max_list, POR_mean_list = [], []\n",
    "in_fn_list = sorted([f for f in os.listdir(data_dir) if f.endswith(\".dat\")])\n",
    "\n",
    "if sample_file_path != None:\n",
    "    with open(sample_file_path, 'r') as f:\n",
    "        sample_file = json.load(f)\n",
    "    sample_object(in_fn_list, sample_file)\n",
    "\n",
    "N_in = len(in_fn_list)\n",
    "\n",
    "DATA_IN = []\n",
    "print(\"caching INPUT ...\")\n",
    "for i in tqdm(range(N_in)):\n",
    "    fn = osp.join(data_dir, in_fn_list[i])\n",
    "    data = pickle.load(open(fn, \"rb\"))\n",
    "    align_part_keys(data)\n",
    "    DATA_IN.append(data)\n",
    "\n",
    "for obj in DATA_IN:\n",
    "    POR_mean, POR_max = POR(obj, n_sample=n_sample_POR)\n",
    "    POR_max_list.append(POR_max)\n",
    "    POR_mean_list.append(POR_mean)\n",
    "\n",
    "# cache the POR results\n",
    "pickle.dump(POR_max_list, open(osp.join(result_dir, 'POR_max_list.pkl'), 'wb'))\n",
    "pickle.dump(POR_mean_list, open(osp.join(result_dir, 'POR_mean_list.pkl'), 'wb'))\n",
    "\n",
    "# remove None values\n",
    "POR_max_list = [x for x in POR_max_list if x is not None]\n",
    "POR_mean_list = [x for x in POR_mean_list if x is not None]\n",
    "\n",
    "result = {\n",
    "    \"Max POR\": np.mean(POR_max_list),\n",
    "    \"Mean POR\": np.mean(POR_mean_list)\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
