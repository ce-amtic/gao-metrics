{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 通用 Object 格式\n",
    "\n",
    "每个 Object 可以抽象成一个 List，List 里面的每一项对应一个刚性部件。每个刚性部件可以用一个字典来描述，字典的格式如下（*代表非必须，依使用的功能而定）：\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"points\": n*3 np.ndarray,\n",
    "    \"joint_data_origin\": [x0, y0, z0],\n",
    "    \"joint_data_direction\": [x1, y1, z1],\n",
    "    \"limit\": [p_min, p_max, r_min, r_max],\n",
    "    \"dfn\": dfs number,\n",
    "    \"dfn_fa\": father's dfs number,\n",
    "    *\"shape_code\": latent code for genSDF,\n",
    "    *\"bbox_l\": [l_x, l_y, l_z],\n",
    "    *\"bbox_center\": [x_c, y_c, z_c],\n",
    "    *\"rho\": number of point per unit cube (1x1x1),\n",
    "    *\"mesh\": triMesh object,\n",
    "}\n",
    "```\n",
    "\n",
    "将该 List 直接使用 pickle 序列化为 .dat 格式，即可作为 ID 计算脚本的输入：\n",
    "\n",
    "```python\n",
    "obj = # List of PartDict\n",
    "path = \"<path_to_directory>\" / \"<name_of_object>.dat\"\n",
    "with open(path, 'wb') as f: \n",
    "    f.write(pickle.dumps(obj))\n",
    "```\n",
    "\n",
    "### Compute Metrics 参数设置\n",
    "\n",
    "该计算脚本基于运行环境：`conda activate pytorch3d`，可以通过 NAP 根目录下 metric_env.sh 构建。\n",
    "\n",
    "请在下面的代码块中填入正确的路径或文件名。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dir:  /root/workspace/csn4bls7v38s73cem970/StorageFurniture_768/2024-11-09_15-42-37/data\n",
      "output_name:  data\n",
      "gt_name:  data_gt\n",
      "N_states:  10\n",
      "N_pcl:  4096\n",
      "result_dir:  /root/workspace/csn4bls7v38s73cem970/StorageFurniture_768/2024-11-09_15-42-37/eval_output\n"
     ]
    }
   ],
   "source": [
    "# data_dir: same as '--data_dir' in instantiation_distance.py\n",
    "data_dir = \"/root/workspace/csn4bls7v38s73cem970/StorageFurniture_768/2024-11-09_15-42-37/data\"\n",
    "# data_dir = \"testin\"\n",
    "\n",
    "# output_name: directory name of '--data_dir' in instantiation_distance.py \n",
    "# gt_name: directory name of '--gt_dir' in instantiation_distance.py\n",
    "output_name = data_dir.split('/')[-1]\n",
    "gt_name = \"data_gt\"\n",
    "# gt_name = \"testgt\"\n",
    "\n",
    "# N_states: same as '--N_states' in instantiation_distance.py\n",
    "# N_pcl: same as '--N_pcl' in instantiation_distance.py\n",
    "# n_sample_POR: number of sample points in the Part Overlapport Ratio (POR) calculation, recommended to be not less than 4096\n",
    "N_states = 10\n",
    "N_pcl = 4096\n",
    "n_sample_POR = 4096\n",
    "\n",
    "# result_dir: same as '--output_dir' in instantiation_distance.py\n",
    "result_dir = '/root/workspace/csn4bls7v38s73cem970/StorageFurniture_768/2024-11-09_15-42-37/eval_output'\n",
    "\n",
    "# sample_file_path: same as '--sample_file_path' in instantiation_distance.py\n",
    "sample_file_path = '/root/workspace/csn4bls7v38s73cem970/eval/selected_files.json'\n",
    "\n",
    "##########\n",
    "print(\"data_dir: \", data_dir)\n",
    "print(\"output_name: \", output_name)\n",
    "print(\"gt_name: \", gt_name)\n",
    "print(\"N_states: \", N_states)\n",
    "print(\"N_pcl: \", N_pcl)\n",
    "print(\"result_dir: \", result_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ID Metrics 计算\n",
    "\n",
    "需要准备好 model output 和 gt files，分别放在两个文件夹下，文件夹里面就是.dat格式保存的obj dict文件，每个文件代表一个物品。\n",
    "参照 `compute_id.sh` 里的格式，填好参数并运行 `instantiation_distance.py`。\n",
    "\n",
    "之后把两个参数中的文件夹名，和计算脚本输出的目录填在下面，运行该代码块即可。\n",
    "\n",
    "### ID Metrics 解释\n",
    "\n",
    "- minimum matching distance (MMD) 对于每个生成样本，在源数据中找与它距离最小的作为match（minimum matching）。每个生成样本只统计和match的距离，对所有距离取平均得到这一指标。**描述个体维度的重建质量，数值越小越好。**\n",
    "- coverage (COV) 计算所有match的去重数量，除以输入样本的总数。**描述模型覆盖率，数值越大越好**。\n",
    "- 1-nearest neighbor accuracy (1-NNA) 直观上说，该指标的数值等于错误匹配的样本数量。**描述分布的相似度，数值越小越好。**\n",
    "\n",
    "1-NNA的计算过程：把输入样本和生成样本合并为一个大集合，对其进行最邻近聚类（1-NN Clustering）。记输入样本为1，生成样本为0，得到gt。再通过最邻近聚类重新预测标签，即把每个样本预测为它1-NN的gt类别，计算预测准确率，得到该值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/pytorch3d/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">data data_gt\n",
       "</pre>\n"
      ],
      "text/plain": [
       "data data_gt\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1-NN-ID-acc': tensor(0.6100),\n",
      " 'lgam_cov-ID': tensor(0.3700),\n",
      " 'lgan_mmd-ID': tensor(0.0500)}\n"
     ]
    }
   ],
   "source": [
    "from utils import eval_ID\n",
    "\n",
    "# evaluate the instantiation distance\n",
    "eval_ID(result_dir, output_name, gt_name, N_states, N_pcl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POR Metric 计算\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "caching INPUT ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:05<00:00, 16.99it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 30.07it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 33.40it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.29it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.42it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 59.68it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.45it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.31it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.81it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.81it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.92it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.02it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.24it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.93it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.19it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.48it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.31it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.41it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.36it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.83it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.22it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.82it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.38it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 33.64it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.40it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 88.23it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.61it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 88.25it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.86it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.15it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.75it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.77it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 54.86it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.30it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.96it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.82it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.46it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 59.04it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.08it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.78it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.76it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.78it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.51it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.80it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 99.35it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.63it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.17it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.89it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.30it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.32it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 29.74it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.21it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.19it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.83it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.34it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.35it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.18it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.86it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.92it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.98it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 121.52it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.37it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.08it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.80it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.88it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.22it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.36it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.42it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.81it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.35it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.32it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.34it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.70it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.87it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.78it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.42it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.42it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.94it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.34it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.30it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.28it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.27it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 191.62it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.16it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.27it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.36it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.84it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 34.35it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.85it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 90.67it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 91.97it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.88it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.19it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.07it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 92.13it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 17.79it/s]\n",
      "Processing on different pose state.: 100%|██████████| 10/10 [00:00<00:00, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Max POR': 0.04392787, 'Mean POR': 0.015015458}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, os.path as osp\n",
    "import pickle, json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from utils import POR\n",
    "from utils import sample_object\n",
    "\n",
    "POR_max_list, POR_mean_list = [], []\n",
    "in_fn_list = sorted([f for f in os.listdir(data_dir) if f.endswith(\".dat\")])\n",
    "\n",
    "if sample_file_path != None:\n",
    "    with open(sample_file_path, 'r') as f:\n",
    "        sample_file = json.load(f)\n",
    "    sample_object(in_fn_list, sample_file)\n",
    "\n",
    "N_in = len(in_fn_list)\n",
    "\n",
    "DATA_IN = []\n",
    "print(\"caching INPUT ...\")\n",
    "for i in tqdm(range(N_in)):\n",
    "    fn = osp.join(data_dir, in_fn_list[i])\n",
    "    data = pickle.load(open(fn, \"rb\"))\n",
    "    DATA_IN.append(data)\n",
    "\n",
    "for obj in DATA_IN:\n",
    "    POR_mean, POR_max = POR(obj, n_sample=n_sample_POR)\n",
    "    POR_max_list.append(POR_max)\n",
    "    POR_mean_list.append(POR_mean)\n",
    "\n",
    "# cache the POR results\n",
    "pickle.dump(POR_max_list, open(osp.join(result_dir, 'POR_max_list.pkl'), 'wb'))\n",
    "pickle.dump(POR_mean_list, open(osp.join(result_dir, 'POR_mean_list.pkl'), 'wb'))\n",
    "\n",
    "result = {\n",
    "    \"Max POR\": np.mean(POR_max_list),\n",
    "    \"Mean POR\": np.mean(POR_mean_list)\n",
    "}\n",
    "\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch3d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
